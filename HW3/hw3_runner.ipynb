{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62c3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffde3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import homework3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74ac9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6d8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f18189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countRight(a,b,epsilon):\n",
    "    if len(a) != len(b):\n",
    "        print(\"It looks like your solution has the wrong length (got \" + str(len(a)) + \", expected \"\n",
    " + str(len(b)) + \")\")\n",
    "        return 0\n",
    "    a_ = np.array(a).flatten()\n",
    "    b_ = np.array(b).flatten()\n",
    "    right = np.abs(a_ - b_) < epsilon\n",
    "    return float(sum(right) / len(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b776b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e79beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"./../datasets/assignment1/train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4103a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9fe3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c51f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef4c9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRatings = [r[2] for r in ratingsTrain]\n",
    "globalAverage = homework3.getGlobalAverage(trainRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0332cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ1():\n",
    "    ga = homework3.getGlobalAverage(trainRatings)\n",
    "\n",
    "    trivialValidMSE = homework3.trivialValidMSE(ratingsValid, ga)\n",
    "    \n",
    "    print(\"average = \" + str(ga))\n",
    "    print(\"validation MSE = \" + str(trivialValidMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413ce857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = 3.6868052631578947\n",
      "validation MSE = 1.680211317922438\n"
     ]
    }
   ],
   "source": [
    "testQ1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c109250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateN(which, alpha, betaU, betaI, lamb, N):\n",
    "    for i in range(N):\n",
    "        alpha = which.alphaUpdate(ratingsTrain, alpha, betaU, betaI, lamb)\n",
    "        betaU = which.betaUUpdate(ratingsPerUser, alpha, betaU, betaI, lamb)\n",
    "        betaI = which.betaIUpdate(ratingsPerItem, alpha, betaU, betaI, lamb)\n",
    "        mse, mseReg = which.msePlusReg(ratingsTrain, alpha, betaU, betaI, lamb)\n",
    "        print(\"Iteration \" + str(i + 1))\n",
    "        print(\"  MSE = \" + str(mse))\n",
    "        print(\"  regularized objective = \" + str(mseReg))\n",
    "    return alpha, betaU, betaI, mse, mseReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68529957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(which):\n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in ratingsPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for b in ratingsPerItem:\n",
    "        betaI[b] = 0\n",
    "\n",
    "    alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "    \n",
    "    alpha, betaU, betaI, mse, mseReg = iterateN(which, alpha, betaU, betaI, 1.0, 1)\n",
    "    validMSE = which.validMSE(ratingsValid, alpha, betaU, betaI)\n",
    "    \n",
    "    return alpha, betaU, betaI, mse, mseReg, validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9567547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ2():\n",
    "    alpha, betaU, betaI, mse, mseReg, validMSE = testModel(homework3)\n",
    "    print(\"validMSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cac96b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "  MSE = 1.0727154704480888\n",
      "  regularized objective = 13249.82842908561\n",
      "validMSE = 1.440670105511255\n"
     ]
    }
   ],
   "source": [
    "testQ2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b673f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ3():\n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in ratingsPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for b in ratingsPerItem:\n",
    "        betaI[b] = 0\n",
    "\n",
    "    alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "    \n",
    "    alpha, betaU, betaI = homework3.goodModel(ratingsTrain, ratingsPerUser, ratingsPerItem, alpha, betaU, betaI)\n",
    "    validMSE = homework3.validMSE(ratingsValid, alpha, betaU, betaI)\n",
    "    \n",
    "    print(\"validMSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ea8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validMSE = 1.43487779932601\n"
     ]
    }
   ],
   "source": [
    "testQ3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddd75a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac0c608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"./../datasets/assignment1/train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "146f9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ4():\n",
    "    readValid, notRead = homework3.generateValidation(allRatings, ratingsValid)\n",
    "    print(\"Should be equal: \" + str((len(readValid), len(notRead), len(ratingsValid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0d6faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be equal: (10000, 10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "testQ4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67f241bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ5():\n",
    "    return1 = homework3.baseLineStrategy(mostPopular, totalRead)\n",
    "    better = homework3.improvedStrategy(mostPopular, totalRead)\n",
    "    \n",
    "    readValid, notRead = homework3.generateValidation(allRatings, ratingsValid)\n",
    "    \n",
    "    correctA = homework3.evaluateStrategy(return1, readValid, notRead)\n",
    "    correctB = homework3.evaluateStrategy(better, readValid, notRead)\n",
    "    \n",
    "    print(\"Accuracy (simple strategy) = \" + str(correctA))\n",
    "    print(\"Accuracy (better strategy) = \" + str(correctB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57f729d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (simple strategy) = 0.7115\n",
      "Accuracy (better strategy) = 0.7375\n"
     ]
    }
   ],
   "source": [
    "testQ5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a29bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ6():\n",
    "    readValid, notRead = homework3.generateValidation(allRatings, ratingsValid)\n",
    "    \n",
    "    for (u,b) in list(readValid)[:20] + list(notRead)[:20]:\n",
    "        a = homework3.jaccardThresh(u,b,ratingsPerItem,ratingsPerUser)\n",
    "        print(\"Jaccard-based predictor for \" + str((u,b)) + \" = \" + str(a))\n",
    "\n",
    "    # This is slow (so the autograder doesn't run it) but you should run it at home once you have a good solution\n",
    "    # homework3.writePredictionsRead(ratingsPerItem, ratingsPerUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e4ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard-based predictor for ('u14474538', 'b26940296') = 1\n",
      "Jaccard-based predictor for ('u58019057', 'b42920311') = 1\n",
      "Jaccard-based predictor for ('u41520063', 'b10032964') = 1\n",
      "Jaccard-based predictor for ('u42166306', 'b12204510') = 0\n",
      "Jaccard-based predictor for ('u33364550', 'b88805343') = 1\n",
      "Jaccard-based predictor for ('u64867256', 'b62292824') = 1\n",
      "Jaccard-based predictor for ('u14921259', 'b05819688') = 1\n",
      "Jaccard-based predictor for ('u87799363', 'b86214899') = 0\n",
      "Jaccard-based predictor for ('u75351019', 'b66664015') = 1\n",
      "Jaccard-based predictor for ('u85235376', 'b87202282') = 0\n",
      "Jaccard-based predictor for ('u36945000', 'b54695184') = 1\n",
      "Jaccard-based predictor for ('u45431809', 'b08545824') = 1\n",
      "Jaccard-based predictor for ('u59074406', 'b82853645') = 1\n",
      "Jaccard-based predictor for ('u17931540', 'b00781753') = 1\n",
      "Jaccard-based predictor for ('u16619308', 'b55847701') = 1\n",
      "Jaccard-based predictor for ('u36649549', 'b78008834') = 1\n",
      "Jaccard-based predictor for ('u00120164', 'b59770276') = 0\n",
      "Jaccard-based predictor for ('u06885377', 'b59428284') = 1\n",
      "Jaccard-based predictor for ('u23428464', 'b09049778') = 1\n",
      "Jaccard-based predictor for ('u60611691', 'b33798237') = 0\n",
      "Jaccard-based predictor for ('u34480142', 'b74929101') = 1\n",
      "Jaccard-based predictor for ('u95360464', 'b68713172') = 0\n",
      "Jaccard-based predictor for ('u94589700', 'b41642312') = 0\n",
      "Jaccard-based predictor for ('u09076589', 'b10450231') = 0\n",
      "Jaccard-based predictor for ('u95255205', 'b74856026') = 0\n",
      "Jaccard-based predictor for ('u55932398', 'b66348359') = 1\n",
      "Jaccard-based predictor for ('u30775636', 'b45359881') = 0\n",
      "Jaccard-based predictor for ('u17502990', 'b97384261') = 0\n",
      "Jaccard-based predictor for ('u83871157', 'b02994747') = 1\n",
      "Jaccard-based predictor for ('u87411957', 'b50025166') = 0\n",
      "Jaccard-based predictor for ('u49798579', 'b59192498') = 0\n",
      "Jaccard-based predictor for ('u59622201', 'b64336742') = 0\n",
      "Jaccard-based predictor for ('u52364276', 'b82423762') = 0\n",
      "Jaccard-based predictor for ('u59369949', 'b72034166') = 0\n",
      "Jaccard-based predictor for ('u31353423', 'b76829808') = 0\n",
      "Jaccard-based predictor for ('u86092020', 'b49822219') = 0\n",
      "Jaccard-based predictor for ('u89590708', 'b53220424') = 0\n",
      "Jaccard-based predictor for ('u79527641', 'b26924525') = 1\n",
      "Jaccard-based predictor for ('u88546784', 'b12920844') = 1\n",
      "Jaccard-based predictor for ('u50478930', 'b77265663') = 0\n"
     ]
    }
   ],
   "source": [
    "testQ6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c1e31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Category prediction                            #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aba9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for d in readGz(\"../datasets/assignment1/train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "    # Just use a little data to make things faster...\n",
    "    if len(data) > 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd6a3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16e35313",
   "metadata": {},
   "outputs": [],
   "source": [
    "NW = 500 # dictionary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3a2eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[1] for x in counts[:NW]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "445775f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e13c5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ7():\n",
    "    f1 = homework3.featureCat(data[0], words, wordId, wordSet)\n",
    "    \n",
    "    print(\"Feature vector = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46cb8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector = [0, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "testQ7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8230c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ8():\n",
    "    X = [homework3.featureCat(d, words, wordId, wordSet) for d in data]\n",
    "    y = [d['genreID'] for d in data]\n",
    "    \n",
    "    Xtrain = X[:9*len(X)//10]\n",
    "    ytrain = y[:9*len(y)//10]\n",
    "    Xvalid = X[9*len(X)//10:]\n",
    "    yvalid = y[9*len(y)//10:]\n",
    "    \n",
    "    mod = linear_model.LogisticRegression(C=1)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    pred = mod.predict(Xvalid)\n",
    "    correctA = pred == yvalid\n",
    "    correctA = sum(correctA) / len(correctA)\n",
    "    \n",
    "    X = homework3.betterFeatures(data)\n",
    "    Xtrain = X[:9*len(X)//10]\n",
    "    Xvalid = X[9*len(X)//10:]\n",
    "    \n",
    "    mod = linear_model.LogisticRegression(C=1)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    pred = mod.predict(Xvalid)\n",
    "    correctB = pred == yvalid\n",
    "    correctB = sum(correctB) / len(correctB)\n",
    "    \n",
    "    sc = correctA < (correctB * 0.99)\n",
    "\n",
    "    data_test = []\n",
    "    for d in readGz(\"../datasets/assignment1/test_Category.json.gz\"):\n",
    "        data_test.append(d)\n",
    "    \n",
    "    Xtest = homework3.betterFeatures(data_test)\n",
    "    pred_test = mod.predict(Xtest)\n",
    "    \n",
    "    homework3.writePredictionsCategory(pred_test)\n",
    "    \n",
    "    if sc:\n",
    "        print(\"Looks like your solution is better\")\n",
    "    else:\n",
    "        print(\"Looks like your solution is not better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e820fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedramaghazadeh/miniconda3/envs/echollm/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/pedramaghazadeh/miniconda3/envs/echollm/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like your solution is better\n"
     ]
    }
   ],
   "source": [
    "testQ8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bd24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
